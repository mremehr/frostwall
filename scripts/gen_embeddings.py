#!/usr/bin/env python3
"""Generate CLIP text embeddings for wallpaper categories."""
import os
import sys

# Disable progress bars
os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"

import warnings
warnings.filterwarnings("ignore")

import torch
from transformers import CLIPProcessor, CLIPModel, logging
logging.set_verbosity_error()

CATEGORIES = {
    "nature": ["a photograph of natural scenery", "beautiful nature landscape with plants"],
    "forest": ["a dense forest with tall trees", "woodland photography with green foliage"],
    "ocean": ["ocean waves and sea water", "beach and coastline photography"],
    "mountain": ["mountain peaks and alpine landscape", "rocky mountains with snow"],
    "desert": ["sandy desert landscape with dunes", "arid desert environment"],
    "tropical": ["tropical beach with palm trees", "exotic tropical paradise"],
    "city": ["urban cityscape with buildings and skyscrapers", "city skyline at night"],
    "urban": ["urban street scene", "metropolitan urban environment"],
    "architecture": ["architectural photography of buildings", "beautiful architecture"],
    "abstract": ["abstract art with geometric patterns", "surreal abstract digital artwork"],
    "minimal": ["minimalist design with clean simple lines", "sparse minimalist composition"],
    "geometric": ["geometric patterns and shapes", "mathematical geometric artwork"],
    "vintage": ["vintage retro style photography", "old fashioned vintage aesthetic"],
    "retro": ["retro 80s 90s aesthetic", "synthwave retro style artwork"],
    "dark": ["dark moody atmosphere", "shadowy low-key scene at night"],
    "bright": ["bright and vibrant colorful scene", "sunny cheerful high-key photography"],
    "sunset": ["sunset sky with golden orange colors", "golden hour twilight photography"],
    "pastel": ["soft pastel colors", "gentle muted pastel tones"],
    "vibrant": ["vibrant saturated colors", "colorful high contrast imagery"],
    "anime": ["anime art style illustration", "japanese animation manga artwork"],
    "cyberpunk": ["cyberpunk neon city aesthetic", "futuristic technology neon lights"],
    "fantasy": ["fantasy magical landscape", "mythical enchanted fantasy artwork"],
    "space": ["outer space with stars and galaxies", "cosmic nebula and planets"],
    "cozy": ["cozy warm comfortable interior", "homey relaxing atmosphere"],
    "portrait": ["portrait orientation vertical image", "tall vertical composition"],
    "landscape_orientation": ["landscape orientation horizontal wide image", "panoramic wide view"],
}

def main():
    print("Loading CLIP model...", file=sys.stderr)
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

    print("Generating embeddings...", file=sys.stderr)
    embeddings = {}
    for cat, descs in CATEGORIES.items():
        inputs = processor(text=descs, return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            # Get text embeddings via the text projection
            outputs = model.text_model(
                input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"],
            )
            # Use pooler_output and project to shared embedding space
            pooled = outputs.pooler_output
            text_embeds = model.text_projection(pooled)
            # Average embeddings from all descriptions
            avg = text_embeds.mean(dim=0)
            # Normalize to unit vector
            avg = avg / avg.norm()
            embeddings[cat] = avg.tolist()

    # Output Rust code
    print("//! Pre-computed CLIP text embeddings for wallpaper categories.")
    print("//! Generated by scripts/gen_embeddings.py - DO NOT EDIT MANUALLY")
    print("")
    print("/// CLIP embedding dimension (ViT-B/32)")
    print("pub const EMBEDDING_DIM: usize = 512;")
    print("")
    print("/// Pre-computed normalized text embeddings for each category.")
    print("pub const CATEGORY_EMBEDDINGS: &[(&str, [f32; EMBEDDING_DIM])] = &[")

    for cat in sorted(embeddings.keys()):
        emb = embeddings[cat]
        print(f'    ("{cat}", [')
        for i in range(0, len(emb), 8):
            chunk = ", ".join(f"{v: .8f}" for v in emb[i : i + 8])
            print(f"        {chunk},")
        print("    ]),")

    print("];")
    print("")
    print("/// List of available category names")
    print("pub fn available_categories() -> Vec<&'static str> {")
    print("    CATEGORY_EMBEDDINGS.iter().map(|(name, _)| *name).collect()")
    print("}")

    sys.stderr.write(f"Generated {len(embeddings)} category embeddings.\n")
    sys.stderr.flush()


if __name__ == "__main__":
    main()
